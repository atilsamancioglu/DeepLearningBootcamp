{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ae4aba-77b3-40d0-bcf3-bf463af91656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b862e6ac-8c8f-4135-b27c-2bdb235bd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce26d88-6f50-4087-8848-007b5a53c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b54867-bad8-4fde-a565-722123d3ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04593dbd-e65c-4c4e-9878-b048969fe36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "#NUM_WORKERS = 0 # you can make this 0 if you get any error on mac silicon\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "  # Use ImageFolder to create dataset(s)\n",
    "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "  # Get class names\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  # Turn images into data loaders\n",
    "  train_dataloader = DataLoader(\n",
    "      train_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "  test_dataloader = DataLoader(\n",
    "      test_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False, # don't need to shuffle test data\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731b60be-71b5-4ebb-ae00-4724450b73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DesertClassifier(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)  # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units * 16 * 16,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c16c98f-20fa-46c0-bde7-0da31ea5e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metrics across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item() / len(test_pred_labels))\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          experiment_name=\"experiment\"):\n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "               }\n",
    "\n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn)\n",
    "\n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        # Ensure all data is moved to CPU and converted to float for storage\n",
    "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "        \n",
    "        writer = SummaryWriter(log_dir=f\"runs/{experiment_name}\")\n",
    "        # Add loss results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Loss\", \n",
    "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"test_loss\": test_loss},\n",
    "                           global_step=epoch)\n",
    "\n",
    "        # Add accuracy results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc}, \n",
    "                           global_step=epoch)\n",
    "        \n",
    "        # Track the PyTorch model architecture\n",
    "        writer.add_graph(model=model, \n",
    "                         # Pass in an example input\n",
    "                         input_to_model=torch.randn(32, 3, 64, 64))\n",
    "    \n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb578ca7-fbc3-489c-b763-9691467c3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    NUM_EPOCHS = 2\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    # Setup directories\n",
    "    train_dir = \"data/desert101/train\"\n",
    "    test_dir = \"data/desert101/test\"\n",
    "\n",
    "    #device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Create transforms\n",
    "    data_transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Create DataLoaders with help from data_setup.py\n",
    "    train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        transform=data_transform,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # Create model with help from model_builder.py\n",
    "    model = DesertClassifier(\n",
    "        input_shape=3,\n",
    "        hidden_units=10,\n",
    "        output_shape=len(class_names)\n",
    "    )\n",
    "\n",
    "    model2 = DesertClassifier(\n",
    "        input_shape=3,\n",
    "        hidden_units=32,\n",
    "        output_shape=len(class_names)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb0c46f-44a3-4e09-b4a4-1125210c346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ee3111-f87c-433f-9434-accc0eb6fbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.3903 | train_acc: 0.2402 | test_loss: 1.3834 | test_acc: 0.1979\n",
      "Epoch: 2 | train_loss: 1.3858 | train_acc: 0.2317 | test_loss: 1.3850 | test_acc: 0.2083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.390274953842163, 1.3857890129089356],\n",
       " 'train_acc': [0.24017857142857144, 0.23169642857142855],\n",
       " 'test_loss': [1.3834332625071208, 1.3849695126215618],\n",
       " 'test_acc': [0.19791666666666666, 0.20833333333333334]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    experiment_name=\"hidden_units_10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ece2170-4d5b-46b6-a2bc-26ec97bcf081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.3900 | train_acc: 0.2661 | test_loss: 1.4103 | test_acc: 0.2083\n",
      "Epoch: 2 | train_loss: 1.3947 | train_acc: 0.2304 | test_loss: 1.3909 | test_acc: 0.1979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.3900075674057006, 1.394719088077545],\n",
       " 'train_acc': [0.26607142857142857, 0.23035714285714284],\n",
       " 'test_loss': [1.4102689822514851, 1.3908943732579548],\n",
       " 'test_acc': [0.20833333333333334, 0.19791666666666666]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    model=model2,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=torch.optim.Adam(model2.parameters(), lr=LEARNING_RATE),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    experiment_name=\"hidden_units_32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4cffeb1-d219-4726-8a34-415e5f3ebd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3da3eb783b053281\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3da3eb783b053281\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs # run session with the \"runs/\" directory (runs directory is created automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facd484-571b-43fa-91f2-2b1a4b840414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
